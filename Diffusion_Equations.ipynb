{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c577397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost:  41.05505310046363\n",
      "Final cost:  3.523938720339645\n",
      "Max absolute difference between the analytical solution and the network: 0.362021\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import jacobian,hessian,grad\n",
    "import autograd.numpy.random as npr\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "## Set up the network\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def deep_neural_network(deep_params, x):\n",
    "    # x is now a point and a 1D numpy array; make it a column vector\n",
    "    num_coordinates = np.size(x,0)\n",
    "    x = x.reshape(num_coordinates,-1)\n",
    "\n",
    "    num_points = np.size(x,1)\n",
    "\n",
    "    # N_hidden is the number of hidden layers\n",
    "    N_hidden = np.size(deep_params) - 1 # -1 since params consist of parameters to all the hidden layers AND the output layer\n",
    "\n",
    "    # Assume that the input layer does nothing to the input x\n",
    "    x_input = x\n",
    "    x_prev = x_input\n",
    "\n",
    "    ## Hidden layers:\n",
    "\n",
    "    for l in range(N_hidden):\n",
    "        # From the list of parameters P; find the correct weigths and bias for this layer\n",
    "        w_hidden = deep_params[l]\n",
    "\n",
    "        # Add a row of ones to include bias\n",
    "        x_prev = np.concatenate((np.ones((1,num_points)), x_prev ), axis = 0)\n",
    "\n",
    "        z_hidden = np.matmul(w_hidden, x_prev)\n",
    "        x_hidden = sigmoid(z_hidden)\n",
    "\n",
    "        # Update x_prev such that next layer can use the output from this layer\n",
    "        x_prev = x_hidden\n",
    "\n",
    "    ## Output layer:\n",
    "\n",
    "    # Get the weights and bias for this layer\n",
    "    w_output = deep_params[-1]\n",
    "\n",
    "    # Include bias:\n",
    "    x_prev = np.concatenate((np.ones((1,num_points)), x_prev), axis = 0)\n",
    "\n",
    "    z_output = np.matmul(w_output, x_prev)\n",
    "    x_output = z_output\n",
    "\n",
    "    return x_output[0][0]\n",
    "\n",
    "## Define the trial solution and cost function\n",
    "def u(x):\n",
    "    return np.sin(np.pi*x)\n",
    "\n",
    "def g_trial(point,P):\n",
    "    x,t = point\n",
    "    return (1-t)*u(x) + x*(1-x)*t*deep_neural_network(P,point)\n",
    "\n",
    "# The right side of the ODE:\n",
    "def f(point):\n",
    "    return 0.\n",
    "\n",
    "# The cost function:\n",
    "def cost_function(P, x, t):\n",
    "    cost_sum = 0\n",
    "\n",
    "    g_t_jacobian_func = jacobian(g_trial)\n",
    "    g_t_hessian_func = hessian(g_trial)\n",
    "\n",
    "    for x_ in x:\n",
    "        for t_ in t:\n",
    "            point = np.array([x_,t_])\n",
    "\n",
    "            g_t = g_trial(point,P)\n",
    "            g_t_jacobian = g_t_jacobian_func(point,P)\n",
    "            g_t_hessian = g_t_hessian_func(point,P)\n",
    "\n",
    "            g_t_dt = g_t_jacobian[1]\n",
    "            g_t_d2x = g_t_hessian[0][0]\n",
    "\n",
    "            func = f(point)\n",
    "\n",
    "            err_sqr = ( (g_t_dt - g_t_d2x) - func)**2\n",
    "            cost_sum += err_sqr\n",
    "\n",
    "    return cost_sum /( np.size(x)*np.size(t) )\n",
    "\n",
    "## For comparison, define the analytical solution\n",
    "def g_analytic(point):\n",
    "    x,t = point\n",
    "    return np.exp(-np.pi**2*t)*np.sin(np.pi*x)\n",
    "\n",
    "## Set up a function for training the network to solve for the equation\n",
    "def solve_pde_deep_neural_network(x,t, num_neurons, num_iter, lmb):\n",
    "    ## Set up initial weigths and biases\n",
    "    N_hidden = np.size(num_neurons)\n",
    "\n",
    "    ## Set up initial weigths and biases\n",
    "\n",
    "    # Initialize the list of parameters:\n",
    "    P = [None]*(N_hidden + 1) # + 1 to include the output layer\n",
    "\n",
    "    P[0] = npr.randn(num_neurons[0], 2 + 1 ) # 2 since we have two points, +1 to include bias\n",
    "    for l in range(1,N_hidden):\n",
    "        P[l] = npr.randn(num_neurons[l], num_neurons[l-1] + 1) # +1 to include bias\n",
    "\n",
    "    # For the output layer\n",
    "    P[-1] = npr.randn(1, num_neurons[-1] + 1 ) # +1 since bias is included\n",
    "\n",
    "    print('Initial cost: ',cost_function(P, x, t))\n",
    "\n",
    "    cost_function_grad = grad(cost_function,0)\n",
    "\n",
    "    # Let the update be done num_iter times\n",
    "    for i in range(num_iter):\n",
    "        cost_grad =  cost_function_grad(P, x , t)\n",
    "\n",
    "        for l in range(N_hidden+1):\n",
    "            P[l] = P[l] - lmb * cost_grad[l]\n",
    "\n",
    "    print('Final cost: ',cost_function(P, x, t))\n",
    "\n",
    "    return P\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ### Use the neural network:\n",
    "    npr.seed(15)\n",
    "\n",
    "    ## Decide the vales of arguments to the function to solve\n",
    "    Nx = 10; Nt = 10\n",
    "    x = np.linspace(0, 1, Nx)\n",
    "    t = np.linspace(0,1,Nt)\n",
    "\n",
    "    ## Set up the parameters for the network\n",
    "    num_hidden_neurons = [100, 25]\n",
    "    num_iter = 250\n",
    "    lmb = 0.01\n",
    "\n",
    "    P = solve_pde_deep_neural_network(x,t, num_hidden_neurons, num_iter, lmb)\n",
    "\n",
    "    ## Store the results\n",
    "    g_dnn_ag = np.zeros((Nx, Nt))\n",
    "    G_analytical = np.zeros((Nx, Nt))\n",
    "    for i,x_ in enumerate(x):\n",
    "        for j, t_ in enumerate(t):\n",
    "            point = np.array([x_, t_])\n",
    "            g_dnn_ag[i,j] = g_trial(point,P)\n",
    "\n",
    "            G_analytical[i,j] = g_analytic(point)\n",
    "\n",
    "    # Find the map difference between the analytical and the computed solution\n",
    "    diff_ag = np.abs(g_dnn_ag - G_analytical)\n",
    "    print('Max absolute difference between the analytical solution and the network: %g'%np.max(diff_ag))\n",
    "\n",
    "    ## Plot the solutions in two dimensions, that being in position and time\n",
    "\n",
    "    T,X = np.meshgrid(t,x)\n",
    "\n",
    "    ## Take some slices of the 3D plots just to see the solutions at particular times\n",
    "    indx1 = 0\n",
    "    indx2 = int(Nt/2)\n",
    "    indx3 = Nt-1\n",
    "\n",
    "    t1 = t[indx1]\n",
    "    t2 = t[indx2]\n",
    "    t3 = t[indx3]\n",
    "\n",
    "    # Slice the results from the DNN\n",
    "    res1 = g_dnn_ag[:,indx1]\n",
    "    res2 = g_dnn_ag[:,indx2]\n",
    "    res3 = g_dnn_ag[:,indx3]\n",
    "\n",
    "    # Slice the analytical results\n",
    "    res_analytical1 = G_analytical[:,indx1]\n",
    "    res_analytical2 = G_analytical[:,indx2]\n",
    "    res_analytical3 = G_analytical[:,indx3]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35141316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "147f51aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t=0</th>\n",
       "      <th>t = 0.1</th>\n",
       "      <th>t = 0.2</th>\n",
       "      <th>t=0.3</th>\n",
       "      <th>t=0.4</th>\n",
       "      <th>t=0.5</th>\n",
       "      <th>t=0.6</th>\n",
       "      <th>t=0.7</th>\n",
       "      <th>t=0.8</th>\n",
       "      <th>t=0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.420201e-01</td>\n",
       "      <td>2.379594e-01</td>\n",
       "      <td>1.453307e-01</td>\n",
       "      <td>6.944661e-02</td>\n",
       "      <td>1.456129e-02</td>\n",
       "      <td>-1.762659e-02</td>\n",
       "      <td>-2.886317e-02</td>\n",
       "      <td>-2.430186e-02</td>\n",
       "      <td>-1.107434e-02</td>\n",
       "      <td>0.004362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.427876e-01</td>\n",
       "      <td>4.487634e-01</td>\n",
       "      <td>2.756915e-01</td>\n",
       "      <td>1.338537e-01</td>\n",
       "      <td>3.197769e-02</td>\n",
       "      <td>-2.651291e-02</td>\n",
       "      <td>-4.617949e-02</td>\n",
       "      <td>-3.886062e-02</td>\n",
       "      <td>-1.895689e-02</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>6.063970e-01</td>\n",
       "      <td>3.746768e-01</td>\n",
       "      <td>1.849896e-01</td>\n",
       "      <td>4.967631e-02</td>\n",
       "      <td>-2.687861e-02</td>\n",
       "      <td>-5.258884e-02</td>\n",
       "      <td>-4.534076e-02</td>\n",
       "      <td>-2.466313e-02</td>\n",
       "      <td>-0.004204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.848078e-01</td>\n",
       "      <td>6.908270e-01</td>\n",
       "      <td>4.287770e-01</td>\n",
       "      <td>2.148906e-01</td>\n",
       "      <td>6.330457e-02</td>\n",
       "      <td>-2.185087e-02</td>\n",
       "      <td>-5.136040e-02</td>\n",
       "      <td>-4.661662e-02</td>\n",
       "      <td>-2.909614e-02</td>\n",
       "      <td>-0.012795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.848078e-01</td>\n",
       "      <td>6.909438e-01</td>\n",
       "      <td>4.299543e-01</td>\n",
       "      <td>2.180503e-01</td>\n",
       "      <td>6.886113e-02</td>\n",
       "      <td>-1.478122e-02</td>\n",
       "      <td>-4.501069e-02</td>\n",
       "      <td>-4.337207e-02</td>\n",
       "      <td>-3.031215e-02</td>\n",
       "      <td>-0.018730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>6.063907e-01</td>\n",
       "      <td>3.772322e-01</td>\n",
       "      <td>1.925409e-01</td>\n",
       "      <td>6.338778e-02</td>\n",
       "      <td>-8.972568e-03</td>\n",
       "      <td>-3.585984e-02</td>\n",
       "      <td>-3.587517e-02</td>\n",
       "      <td>-2.625592e-02</td>\n",
       "      <td>-0.017899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.427876e-01</td>\n",
       "      <td>4.479390e-01</td>\n",
       "      <td>2.774041e-01</td>\n",
       "      <td>1.411312e-01</td>\n",
       "      <td>4.644019e-02</td>\n",
       "      <td>-6.473853e-03</td>\n",
       "      <td>-2.604382e-02</td>\n",
       "      <td>-2.566326e-02</td>\n",
       "      <td>-1.787073e-02</td>\n",
       "      <td>-0.010852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.420201e-01</td>\n",
       "      <td>2.363573e-01</td>\n",
       "      <td>1.447846e-01</td>\n",
       "      <td>7.222903e-02</td>\n",
       "      <td>2.209091e-02</td>\n",
       "      <td>-5.719394e-03</td>\n",
       "      <td>-1.548620e-02</td>\n",
       "      <td>-1.411162e-02</td>\n",
       "      <td>-8.322539e-03</td>\n",
       "      <td>-0.002751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>1.088575e-16</td>\n",
       "      <td>9.525031e-17</td>\n",
       "      <td>8.164312e-17</td>\n",
       "      <td>6.803593e-17</td>\n",
       "      <td>5.442875e-17</td>\n",
       "      <td>4.082156e-17</td>\n",
       "      <td>2.721437e-17</td>\n",
       "      <td>1.360719e-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t=0       t = 0.1       t = 0.2         t=0.3         t=0.4  \\\n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1  3.420201e-01  2.379594e-01  1.453307e-01  6.944661e-02  1.456129e-02   \n",
       "2  6.427876e-01  4.487634e-01  2.756915e-01  1.338537e-01  3.197769e-02   \n",
       "3  8.660254e-01  6.063970e-01  3.746768e-01  1.849896e-01  4.967631e-02   \n",
       "4  9.848078e-01  6.908270e-01  4.287770e-01  2.148906e-01  6.330457e-02   \n",
       "5  9.848078e-01  6.909438e-01  4.299543e-01  2.180503e-01  6.886113e-02   \n",
       "6  8.660254e-01  6.063907e-01  3.772322e-01  1.925409e-01  6.338778e-02   \n",
       "7  6.427876e-01  4.479390e-01  2.774041e-01  1.411312e-01  4.644019e-02   \n",
       "8  3.420201e-01  2.363573e-01  1.447846e-01  7.222903e-02  2.209091e-02   \n",
       "9  1.224647e-16  1.088575e-16  9.525031e-17  8.164312e-17  6.803593e-17   \n",
       "\n",
       "          t=0.5         t=0.6         t=0.7         t=0.8     t=0.9  \n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000  \n",
       "1 -1.762659e-02 -2.886317e-02 -2.430186e-02 -1.107434e-02  0.004362  \n",
       "2 -2.651291e-02 -4.617949e-02 -3.886062e-02 -1.895689e-02  0.002300  \n",
       "3 -2.687861e-02 -5.258884e-02 -4.534076e-02 -2.466313e-02 -0.004204  \n",
       "4 -2.185087e-02 -5.136040e-02 -4.661662e-02 -2.909614e-02 -0.012795  \n",
       "5 -1.478122e-02 -4.501069e-02 -4.337207e-02 -3.031215e-02 -0.018730  \n",
       "6 -8.972568e-03 -3.585984e-02 -3.587517e-02 -2.625592e-02 -0.017899  \n",
       "7 -6.473853e-03 -2.604382e-02 -2.566326e-02 -1.787073e-02 -0.010852  \n",
       "8 -5.719394e-03 -1.548620e-02 -1.411162e-02 -8.322539e-03 -0.002751  \n",
       "9  5.442875e-17  4.082156e-17  2.721437e-17  1.360719e-17  0.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neural_net_pd = pd.DataFrame(g_dnn_ag, columns = [\"t=0\",\"t = 0.1\", \"t = 0.2\", \"t=0.3\", \"t=0.4\",\"t=0.5\",\"t=0.6\",\"t=0.7\",\"t=0.8\",\"t=0.9\"])\n",
    "Neural_net_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4b9141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t=0</th>\n",
       "      <th>t = 0.1</th>\n",
       "      <th>t = 0.2</th>\n",
       "      <th>t=0.3</th>\n",
       "      <th>t=0.4</th>\n",
       "      <th>t=0.5</th>\n",
       "      <th>t=0.6</th>\n",
       "      <th>t=0.7</th>\n",
       "      <th>t=0.8</th>\n",
       "      <th>t=0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.420201e-01</td>\n",
       "      <td>1.142338e-01</td>\n",
       "      <td>3.815376e-02</td>\n",
       "      <td>1.274325e-02</td>\n",
       "      <td>4.256209e-03</td>\n",
       "      <td>1.421562e-03</td>\n",
       "      <td>4.747976e-04</td>\n",
       "      <td>1.585811e-04</td>\n",
       "      <td>5.296563e-05</td>\n",
       "      <td>1.769037e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.427876e-01</td>\n",
       "      <td>2.146893e-01</td>\n",
       "      <td>7.170561e-02</td>\n",
       "      <td>2.394947e-02</td>\n",
       "      <td>7.999056e-03</td>\n",
       "      <td>2.671662e-03</td>\n",
       "      <td>8.923276e-04</td>\n",
       "      <td>2.980349e-04</td>\n",
       "      <td>9.954282e-05</td>\n",
       "      <td>3.324702e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>2.892500e-01</td>\n",
       "      <td>9.660870e-02</td>\n",
       "      <td>3.226703e-02</td>\n",
       "      <td>1.077710e-02</td>\n",
       "      <td>3.599521e-03</td>\n",
       "      <td>1.202230e-03</td>\n",
       "      <td>4.015414e-04</td>\n",
       "      <td>1.341137e-04</td>\n",
       "      <td>4.479359e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.848078e-01</td>\n",
       "      <td>3.289230e-01</td>\n",
       "      <td>1.098594e-01</td>\n",
       "      <td>3.669272e-02</td>\n",
       "      <td>1.225526e-02</td>\n",
       "      <td>4.093224e-03</td>\n",
       "      <td>1.367125e-03</td>\n",
       "      <td>4.566160e-04</td>\n",
       "      <td>1.525085e-04</td>\n",
       "      <td>5.093739e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.848078e-01</td>\n",
       "      <td>3.289230e-01</td>\n",
       "      <td>1.098594e-01</td>\n",
       "      <td>3.669272e-02</td>\n",
       "      <td>1.225526e-02</td>\n",
       "      <td>4.093224e-03</td>\n",
       "      <td>1.367125e-03</td>\n",
       "      <td>4.566160e-04</td>\n",
       "      <td>1.525085e-04</td>\n",
       "      <td>5.093739e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>2.892500e-01</td>\n",
       "      <td>9.660870e-02</td>\n",
       "      <td>3.226703e-02</td>\n",
       "      <td>1.077710e-02</td>\n",
       "      <td>3.599521e-03</td>\n",
       "      <td>1.202230e-03</td>\n",
       "      <td>4.015414e-04</td>\n",
       "      <td>1.341137e-04</td>\n",
       "      <td>4.479359e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.427876e-01</td>\n",
       "      <td>2.146893e-01</td>\n",
       "      <td>7.170561e-02</td>\n",
       "      <td>2.394947e-02</td>\n",
       "      <td>7.999056e-03</td>\n",
       "      <td>2.671662e-03</td>\n",
       "      <td>8.923276e-04</td>\n",
       "      <td>2.980349e-04</td>\n",
       "      <td>9.954282e-05</td>\n",
       "      <td>3.324702e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.420201e-01</td>\n",
       "      <td>1.142338e-01</td>\n",
       "      <td>3.815376e-02</td>\n",
       "      <td>1.274325e-02</td>\n",
       "      <td>4.256209e-03</td>\n",
       "      <td>1.421562e-03</td>\n",
       "      <td>4.747976e-04</td>\n",
       "      <td>1.585811e-04</td>\n",
       "      <td>5.296563e-05</td>\n",
       "      <td>1.769037e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>4.090286e-17</td>\n",
       "      <td>1.366144e-17</td>\n",
       "      <td>4.562882e-18</td>\n",
       "      <td>1.523990e-18</td>\n",
       "      <td>5.090083e-19</td>\n",
       "      <td>1.700074e-19</td>\n",
       "      <td>5.678198e-20</td>\n",
       "      <td>1.896502e-20</td>\n",
       "      <td>6.334263e-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            t=0       t = 0.1       t = 0.2         t=0.3         t=0.4  \\\n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1  3.420201e-01  1.142338e-01  3.815376e-02  1.274325e-02  4.256209e-03   \n",
       "2  6.427876e-01  2.146893e-01  7.170561e-02  2.394947e-02  7.999056e-03   \n",
       "3  8.660254e-01  2.892500e-01  9.660870e-02  3.226703e-02  1.077710e-02   \n",
       "4  9.848078e-01  3.289230e-01  1.098594e-01  3.669272e-02  1.225526e-02   \n",
       "5  9.848078e-01  3.289230e-01  1.098594e-01  3.669272e-02  1.225526e-02   \n",
       "6  8.660254e-01  2.892500e-01  9.660870e-02  3.226703e-02  1.077710e-02   \n",
       "7  6.427876e-01  2.146893e-01  7.170561e-02  2.394947e-02  7.999056e-03   \n",
       "8  3.420201e-01  1.142338e-01  3.815376e-02  1.274325e-02  4.256209e-03   \n",
       "9  1.224647e-16  4.090286e-17  1.366144e-17  4.562882e-18  1.523990e-18   \n",
       "\n",
       "          t=0.5         t=0.6         t=0.7         t=0.8         t=0.9  \n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1  1.421562e-03  4.747976e-04  1.585811e-04  5.296563e-05  1.769037e-05  \n",
       "2  2.671662e-03  8.923276e-04  2.980349e-04  9.954282e-05  3.324702e-05  \n",
       "3  3.599521e-03  1.202230e-03  4.015414e-04  1.341137e-04  4.479359e-05  \n",
       "4  4.093224e-03  1.367125e-03  4.566160e-04  1.525085e-04  5.093739e-05  \n",
       "5  4.093224e-03  1.367125e-03  4.566160e-04  1.525085e-04  5.093739e-05  \n",
       "6  3.599521e-03  1.202230e-03  4.015414e-04  1.341137e-04  4.479359e-05  \n",
       "7  2.671662e-03  8.923276e-04  2.980349e-04  9.954282e-05  3.324702e-05  \n",
       "8  1.421562e-03  4.747976e-04  1.585811e-04  5.296563e-05  1.769037e-05  \n",
       "9  5.090083e-19  1.700074e-19  5.678198e-20  1.896502e-20  6.334263e-21  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_analytical_pd = pd.DataFrame(G_analytical, columns = [\"t=0\",\"t = 0.1\", \"t = 0.2\", \"t=0.3\", \"t=0.4\",\"t=0.5\",\"t=0.6\",\"t=0.7\",\"t=0.8\",\"t=0.9\"])\n",
    "G_analytical_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a3e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
